# Default max number of steps to allow per episode
MAX_STEPS = 10000
# Default enviroment
ENV_ID = 'DeepRotorCustomActionSpaceEnv-v0'
# Entry point for default enviroment
ENTRY_POINT = 'markov.environments.deeprotor_env:DeepRotorCustomActionSpaceEnv'
# Default reward threshold
THRESHOLD = 200

"""
Default action space from re:Invent (6 actions).
"""
model_metadata = {
    "action_space": [
        {
            "steering_angle": 45,
            "speed": 0.8
        },
        {
            "steering_angle": -45,
            "speed": 0.8
        },
        {
            "steering_angle": 0,
            "speed": 0.8
        },
        {
            "steering_angle": 22.5,
            "speed": 0.8
        },
        {
            "steering_angle": -22.5,
            "speed": 0.8
        },
        {
            "steering_angle": 0,
            "speed": 0.4
        }
    ]
}

"""
Default reward function is the centerline.
"""
def reward_function(params):

    target_x = params['target_x']
    target_y = params['target_y']
    target_z = params['target_z']

    X = params['X']
    Y = params['Y']
    Z = params['Z']

    target_in_view = params['target_in_view']
    crashed = params['crashed']

    if crashed:
        reward = 1e-3
    
    

    return float(reward)

    marker_1 = 0.1 * track_width
    marker_2 = 0.25 * track_width
    marker_3 = 0.5 * track_width

    reward = 1e-3
    if distance_from_center <= marker_1:
        reward = 1
    elif distance_from_center <= marker_2:
        reward = 0.5
    elif distance_from_center <= marker_3:
        reward = 0.1
    else:
        reward = 1e-3  # likely crashed/ close to off track

    return float(reward)
